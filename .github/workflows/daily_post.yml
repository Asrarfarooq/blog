name: ðŸ¤– Daily Qubit AI/ML Post

on:
  schedule:
    # Runs twice daily at 8:30 AM CDT (13:30 UTC) and 3:30 PM CDT (20:30 UTC)
    - cron: '30 13,20 * * *' 
  workflow_dispatch: 

jobs:
  generate_and_publish:
    runs-on: ubuntu-latest
    permissions:
      contents: write 
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_TOKEN_AUTO_COMMIT }} 
          fetch-depth: 0 
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: pip install -r requirements.txt
        
      # -----------------------------------------------
      # --- FIX: OLLAMA INSTALLATION ---
      # -----------------------------------------------
      - name: Install Ollama Client (Fixes 'command not found')
        # This downloads and installs the executable, making it available for the next steps
        run: curl -fsSL https://ollama.com/install.sh | sh 

      - name: Pull LLM and Diagnose on Failure
        run: |
          # 1. Ollama was started automatically by the installer. We wait for it to be ready.
          echo "Waiting up to 60 seconds for auto-started Ollama service..."
          for i in {1..12}; do
            if curl -s --fail http://localhost:11434 > /dev/null; then
              echo "Ollama API is running!"
              break
            fi
            echo "Attempt $i: Ollama not ready yet. Waiting 5s..."
            sleep 5
            if [ $i -eq 12 ]; then
              echo "Error: Ollama service failed to start within the timeout."
              # --- DIAGNOSTIC ---
              # If the service fails to even start, dump the logs.
              echo "Dumping service logs after startup failure:"
              sudo journalctl -u ollama.service --no-pager -n 100
              exit 1
            fi
          done

          # 2. Add a final delay for robustness.
          echo "Service is up. Waiting an extra 5 seconds for full initialization..."
          sleep 5

          # 3. Attempt to pull the model. If it fails (thanks to '||'), run our diagnostic commands.
          echo "Attempting to pull the phi3 model..."
          ollama pull phi3:3.8b-mini-4k-instruct || {
            echo "-----------------------------------------------------"
            echo "--> Ollama pull FAILED. Capturing diagnostic info..."
            echo "-----------------------------------------------------"
            
            echo "--> 1. Checking outbound connectivity to ollama.com..."
            curl -v https://ollama.com
            
            echo ""
            echo "--> 2. DUMPING OLLAMA SERVICE LOGS (journalctl):"
            # This is the most important command. It will show the internal error from the service.
            sudo journalctl -u ollama.service --no-pager --all -n 200
            
            echo "-----------------------------------------------------"
            echo "--> End of diagnostic info. Failing the workflow."
            echo "-----------------------------------------------------"
            exit 1
          }
          
          echo "Model pulled successfully. Proceeding to content generation."
          
      - name: Run Content Generation Script (Daily)
        run: python automation_script.py --type daily
        env:
          GH_TOKEN_AUTO_COMMIT: ${{ secrets.GH_TOKEN_AUTO_COMMIT }}